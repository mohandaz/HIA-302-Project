{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPLj6o6/wkV4ZXE4muW4ITO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mohandaz/HIA-302-Project/blob/main/HIA302_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CLone Github Repository : https://github.com/mohandaz/HIA-302-Project"
      ],
      "metadata": {
        "id": "wQQGxpfjI1XS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "KLzPsvyXH9lf",
        "outputId": "0bf9b2fb-c3fb-4cee-9d9b-8cab5e09c587",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'HIA-302-Project' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/mohandaz/HIA-302-Project"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Libraries used"
      ],
      "metadata": {
        "id": "IIIRalphJeNX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import csv\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "dD72gIX4JUEj"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.1 Demonstrate different ways to convert the horse-colic.txt file to horse-colic.csv."
      ],
      "metadata": {
        "id": "aetlHlRCJn4j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "METHOD 1 : Using Pandas to read and write"
      ],
      "metadata": {
        "id": "RycUVl4AiKWO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "N1zLMQ3tFNer"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "# Input and output file paths\n",
        "input_dir = '/content/HIA-302-Project/horse-colic.txt'\n",
        "output_dir = '/content/HIA-302-Project/horse-colic.csv'\n",
        "\n",
        "# Read the TXT file with a preexisting index and header\n",
        "df = pd.read_csv(input_dir, header=None)\n",
        "\n",
        "# Save the DataFrame to a new CSV file\n",
        "df.to_csv(output_dir)\n",
        "\n",
        "print(f\"Conversion completed. CSV file saved at: {output_dir}\")\n"
      ],
      "metadata": {
        "id": "1gptFVahpImH",
        "outputId": "9be1e6e7-246a-4961-c687-6613cb9aafb6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Conversion completed. CSV file saved at: /content/HIA-302-Project/horse-colic.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "METHOD 2: Using CSV to read and Pandas to write"
      ],
      "metadata": {
        "id": "CyoqONPVK1pR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import pandas as pd\n",
        "\n",
        "# Input and output file paths\n",
        "input_file = '/content/HIA-302-Project/horse-colic.txt'\n",
        "output_file = '/content/HIA-302-Project/horse-colic.csv'\n",
        "\n",
        "# Read data using csv module\n",
        "with open(input_file, 'r') as csv_file:\n",
        "    csv_reader = csv.reader(csv_file)\n",
        "    data = list(csv_reader)\n",
        "\n",
        "# Create a DataFrame using pandas\n",
        "df = pd.DataFrame(data, columns=None)\n",
        "\n",
        "# Write to CSV file with empty header and default index\n",
        "df.to_csv(output_file)\n",
        "\n",
        "print(f\"Conversion completed. CSV file saved at: {output_dir}\")"
      ],
      "metadata": {
        "id": "--iNwj7dqd1W",
        "outputId": "26766eb7-4ffe-4206-f238-842ff75cfceb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Conversion completed. CSV file saved at: /content/HIA-302-Project/horse-colic.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 2.2\n",
        " : Demonstrate that the csv file can read in Jupyter Notebook, and the dataset remains the same as the raw dataset.\n"
      ],
      "metadata": {
        "id": "I46WRGQqO4fY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify the path to the CSV file\n",
        "output_dir = '/content/HIA-302-Project/horse-colic.csv'\n",
        "\n",
        "# Read the CSV file into a Pandas DataFrame\n",
        "horse_colic = pd.read_csv(output_dir, index_col=0, header=0)\n",
        "\n",
        "# Display the first few rows of the CSV DataFrame\n",
        "\n",
        "horse_colic.info()\n",
        "horse_colic.head()\n"
      ],
      "metadata": {
        "id": "DpVICmu4qc0_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.3 Replacing the missing values (i.e. with\"?\" with NaN (Not a Number) value in a loaded dataset using python"
      ],
      "metadata": {
        "id": "4ub8vja2qbpc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "horse_colic_with_NaN = horse_colic.replace(\"?\",\"NaN\")\n",
        "horse_colic_with_NaN.head()\n"
      ],
      "metadata": {
        "id": "3b5niecyppOE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.4 Save the latest dataset with NaN as horse_colic_with_Nan.csv and ensure the data frame's row number is not saved into csv file"
      ],
      "metadata": {
        "id": "RVAyEIQi00_O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output_dir = '/content/HIA-302-Project/horse-colic-with-NaN.csv'\n",
        "# Save the DataFrame to a CSV file\n",
        "horse_colic_with_NaN.to_csv(output_dir, index=False)\n",
        "\n",
        "print(f\"CSV file saved at: {output_dir}\")\n",
        "\n",
        "horse_colic_with_NaN.info()"
      ],
      "metadata": {
        "id": "0XkKebWN3Ymw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.5 Rename the header by following the description file (horse-colic.names) with not more than 10 characters i the header title"
      ],
      "metadata": {
        "id": "n7ZlY4QW1LBK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Specify input and output file paths\n",
        "input_dir = '/content/HIA-302-Project/horse-colic-with-NaN.csv'\n",
        "output_dir = '/content/HIA-302-Project/horse-colic-with-title.csv'\n",
        "\n",
        "# Read the DataFrame from the input CSV file\n",
        "df = pd.read_csv(input_dir)\n",
        "\n",
        "# Reset the index of the DataFrame\n",
        "df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# Rename the columns\n",
        "df.columns = [\n",
        "    'Surgery', 'Age', 'Hosp_No', 'Rect_Temp', 'Pulse', 'RR', 'Temp_Ext', 'Peri_pulse',\n",
        "    'Muc_Memb', 'CRT', 'Pain', 'Perist', 'Abd_Distn', 'NGT', 'Naso_Refx', 'NRP',\n",
        "    'Rect_Exm', 'Abd', 'PCV', 'Tot_Prot', 'Abc_App', 'Abc_Protein', 'Outcome',\n",
        "    'Surg_Lesi', 'Lesi_Site', 'Lesi_Type', 'Lesi_Sub', 'Cp_Data'\n",
        "]\n",
        "\n",
        "# Fill NaN values with a default value (for example, 0)\n",
        "df = df.fillna(0)\n",
        "\n",
        "# Specify columns to keep as integers\n",
        "integer_columns = [ 'Surgery', 'Age', 'Hosp_No', 'Pulse', 'RR', 'Peri_pulse',\n",
        "    'Muc_Memb', 'CRT', 'Pain', 'Perist', 'Abd_Distn', 'NGT', 'Naso_Refx',\n",
        "    'Rect_Exm', 'Abd', 'Abc_App', 'Outcome',\n",
        "    'Surg_Lesi', 'Lesi_Site', 'Lesi_Type', 'Lesi_Sub', 'Cp_Data']\n",
        "\n",
        "# Convert specified columns to integers\n",
        "df[integer_columns] = df[integer_columns].astype('int64')\n",
        "\n",
        "# Specify columns to keep as float with 2 decimal places\n",
        "float_columns = ['Rect_Temp', 'Temp_Ext', 'Tot_Prot', 'NRP', 'PCV', 'Abc_Protein']\n",
        "\n",
        "# Convert specified columns to float with 2 decimal places\n",
        "df[float_columns] = df[float_columns].round(2)\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "df.to_csv(output_dir, index=False)\n",
        "\n",
        "# Print a message indicating that the CSV file has been saved\n",
        "print(f\"CSV file saved at: {output_dir}\")\n"
      ],
      "metadata": {
        "id": "FWx1LXF2o6JB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "muionZil5S0u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.6 Save the latest dataset with header title as horse_colic_with_title.csv and ensure the data frame's row number is not saved into csv file."
      ],
      "metadata": {
        "id": "pGj26n8e1acH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.7 Load the horse_colic_with_title.csv file and display list of total NaN at each column in the data set."
      ],
      "metadata": {
        "id": "jisAv-jO1vBD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nan_counts = df.isna().sum()\n",
        "nan_counts_total = df.isna().sum().sum()\n",
        "# Display the total number of NaN values in the DataFrame\n",
        "print(\"Total NaN values in the DataFrame:\", nan_counts_total)\n",
        "\n",
        "# Display the total number of NaN values for each column\n",
        "print(\"Total NaN values in each column:\")\n",
        "print(nan_counts)"
      ],
      "metadata": {
        "id": "FIRu7KnJ5qo5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.8 Visualize the totsl NaN at each column in the dataset with a bar chart and set colour to 'blue' using Metplotlib library"
      ],
      "metadata": {
        "id": "duqutQzA16RY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming nan_counts is your Series with NaN counts for each column\n",
        "nan_counts.plot(kind='bar', color='blue', figsize=(12, 6))\n",
        "\n",
        "# Customize x-axis tick labels\n",
        "plt.xticks(rotation=90, ha='right')  # Set rotation to 0 to keep labels horizontal\n",
        "\n",
        "# Set labels and title\n",
        "plt.xlabel('Columns')\n",
        "plt.ylabel('Number of NaN Values')\n",
        "plt.title('NaN Values in Each Column')\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "EuG_HQR38WDw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "tWePImqD8VTI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.9 Retrive the datatypes for the dataset"
      ],
      "metadata": {
        "id": "bYqPqv6m2Hx2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming your DataFrame is named df\n",
        "data_types = df.dtypes\n",
        "\n",
        "# Display the data types\n",
        "print(\"Data Types:\")\n",
        "print(data_types)"
      ],
      "metadata": {
        "id": "Qjle8KGF9cLj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.10 In this dataset, will it be good idea to delete/drop tha NaN rows? Justify your answer"
      ],
      "metadata": {
        "id": "GAvVUVX82N5G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Assuming your DataFrame is named df\n",
        "missing_percentage = df.isnull().mean() * 100\n",
        "\n",
        "# Display the percentage of missing data for each column\n",
        "print(\"Percentage of missing data in each column:\")\n",
        "print(missing_percentage.round(1).astype(str) + '%')\n"
      ],
      "metadata": {
        "id": "0y_VqgTt9ygn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the overall percentage of missing data\n",
        "overall_missing_percentage = df.isnull().mean().mean() * 100\n",
        "\n",
        "# Display the overall percentage of missing data\n",
        "print(f\"\\nOverall percentage of missing data: {overall_missing_percentage:.2f}%\")\n"
      ],
      "metadata": {
        "id": "38koyo9w9zht"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "LIWgAWiP9xyy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.11 Read and evaluate the following codes in Figure 1. What method is the code using to reduce missing values from 1605 to 0? Justify your answer"
      ],
      "metadata": {
        "id": "ZR02B_5V2ZX3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code is using the SimpleImputer class from scikit-learn (imported in line 3) to reduce the missing values. Specifically, it's using the mean strategy (specified in line 21) to impute missing values. The mean strategy replaces missing values with the mean along each column."
      ],
      "metadata": {
        "id": "zzN9FHR2BHKX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "(1) from numpy import isnan\n",
        "(2) from pandas import read_csv\n",
        "(3) from sklearn.impute import SimpleImputer\n",
        "(4)\n",
        "(5) #load dataset\n",
        "(6) #replace the '?' with NaN\n",
        "(7)\n",
        "(8) # load dataset\n",
        "(9) data = dataframe.values\n",
        "(10)\n",
        "(11) #  Select column excluding the 23rd column\n",
        "(12) totalCol=data.shape[1]\n",
        "(13) ix = [i for i in range (totalCol)if i !=23]\n",
        "(14) X = data[:,ix]\n",
        "(15) y= data[:, 23]\n",
        "(16)\n",
        "(17) # # Print the total number of missing values after excluding the 23rd column\n",
        "(18) print('Missing: %d' % sum(isnan(X).flatten()))\n",
        "(19)\n",
        "(20) ## Create an imputer with the mean strategy\n",
        "(21) imputer = SimpleImputer(strategy='mean')\n",
        "(22) ## Fit the imputer on the data\n",
        "(23) imputer.fit(X)\n",
        "(24) Xtrans = imputer.transform(X)\n",
        "(25)\n",
        "(26) ## Print the total number of missing values after imputati\n",
        "(27) print('Missing: %d' % sum(isnan(Xtrans).flatten()))"
      ],
      "metadata": {
        "id": "dsZL96I_-QJS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.12 Fill out the inline comments marked with hashtags # in lines 8,11,17,20,22. and 26. include the missing codes in line 5 and 6"
      ],
      "metadata": {
        "id": "-jvtJHsA2rL6"
      }
    }
  ]
}